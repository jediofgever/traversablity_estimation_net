{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f18528-1b6d-4996-96a4-78344252f43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu117\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import DatasetFolder\n",
    "from tqdm import tqdm\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53fd2094-83a1-49f2-a959-4ba5f6bf1544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "#from dataset import TerrainDataset\n",
    "from datasetIMU import TerrainDatasetIMU\n",
    "#from pointnet import PointNet\n",
    "#from pointnetCurv import PointNetCurv\n",
    "\n",
    "dataset = TerrainDatasetIMU(root='/home/atas/RESEARCH/traversablity_estimation_net/data_imu',train=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f6029fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model parameters:  198414\n",
      "Number of training samples:  632\n",
      "Number of test samples:  84\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Javascript  # Restrict height of output cell.\n",
    "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "from pointnet_curv import PointnetCurv\n",
    "\n",
    "train_dataset =  TerrainDatasetIMU(root='/home/atas/RESEARCH/traversablity_estimation_net/data_imu', train=True )\n",
    "test_dataset = TerrainDatasetIMU(root='/home/atas/RESEARCH/traversablity_estimation_net/data_imu', train=False)\n",
    "\n",
    "batch_size = 1\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "model = PointnetCurv()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "#criterion = torch.nn.MSELoss()  # Mean Squared Error Loss Function\n",
    "criterion = torch.nn.L1Loss()  # Mean Absolute Error (L1 Loss Function)\n",
    "#criterion = torch.nn.SmoothL1Loss()  # Huber Loss Function000000\n",
    "\n",
    "\n",
    "# print number of model parameters\n",
    "print(\"Number of model parameters: \", sum([p.numel() for p in model.parameters()]))\n",
    "\n",
    "# print number of training samples\n",
    "print(\"Number of training samples: \", len(train_dataset))\n",
    "print(\"Number of test samples: \", len(test_dataset))\n",
    "\n",
    "def train(model, optimizer, loader):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for data in loader:\n",
    "        optimizer.zero_grad()                   # Clear gradients.\n",
    "        # reshape to have 1 at the end\n",
    "        data.pos = data.pos.reshape((data.pos.shape[0], data.pos.shape[1], 1))\n",
    "        \n",
    "        # make imu view as batch size x 13\n",
    "        data.edge_attr = data.edge_attr.view(-1, 13)\n",
    "        \n",
    "        logits = model(data.pos, data.edge_attr, data.batch)                # Forward pass.\n",
    "        loss = criterion(logits, data.y)        # Loss computation.\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, loader):\n",
    "    model.eval()\n",
    "\n",
    "    mae = 0.0\n",
    "    for data in loader:\n",
    "        data.pos = data.pos.reshape((data.pos.shape[0], data.pos.shape[1], 1))\n",
    "        data.edge_attr = data.edge_attr.view(-1, 13)\n",
    "\n",
    "        pred = model(data.pos, data.edge_attr, data.batch)\n",
    "        \n",
    "        mae += criterion(pred, data.y)        # Loss computation.\n",
    "\n",
    "    mae = mae / len(loader)   \n",
    "    # convert error to percentage accuracy\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "670dec50-952b-4115-b79d-b302b1b960b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 166.3781, MAE: 0.1895\n",
      "Epoch: 02, Loss: 135.4149, MAE: 0.2208\n",
      "Epoch: 03, Loss: 129.1784, MAE: 0.1987\n",
      "Epoch: 04, Loss: 123.0148, MAE: 0.2299\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/atas/RESEARCH/traversablity_estimation_net/scripts/pointnet_imu_regression.ipynb Cell 4\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/atas/RESEARCH/traversablity_estimation_net/scripts/pointnet_imu_regression.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Save every 10th epoch model.\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/atas/RESEARCH/traversablity_estimation_net/scripts/pointnet_imu_regression.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m201\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/atas/RESEARCH/traversablity_estimation_net/scripts/pointnet_imu_regression.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     loss \u001b[39m=\u001b[39m train(model, optimizer, train_loader)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/atas/RESEARCH/traversablity_estimation_net/scripts/pointnet_imu_regression.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     mae \u001b[39m=\u001b[39m test(model, test_loader)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/atas/RESEARCH/traversablity_estimation_net/scripts/pointnet_imu_regression.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mif\u001b[39;00m epoch \u001b[39m%\u001b[39m \u001b[39m50\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;32m/home/atas/RESEARCH/traversablity_estimation_net/scripts/pointnet_imu_regression.ipynb Cell 4\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/atas/RESEARCH/traversablity_estimation_net/scripts/pointnet_imu_regression.ipynb#W3sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# make imu view as batch size x 13\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/atas/RESEARCH/traversablity_estimation_net/scripts/pointnet_imu_regression.ipynb#W3sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m data\u001b[39m.\u001b[39medge_attr \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39medge_attr\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m13\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/atas/RESEARCH/traversablity_estimation_net/scripts/pointnet_imu_regression.ipynb#W3sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m logits \u001b[39m=\u001b[39m model(data\u001b[39m.\u001b[39;49mpos, data\u001b[39m.\u001b[39;49medge_attr, data\u001b[39m.\u001b[39;49mbatch)                \u001b[39m# Forward pass.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/atas/RESEARCH/traversablity_estimation_net/scripts/pointnet_imu_regression.ipynb#W3sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(logits, data\u001b[39m.\u001b[39my)        \u001b[39m# Loss computation.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/atas/RESEARCH/traversablity_estimation_net/scripts/pointnet_imu_regression.ipynb#W3sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/RESEARCH/traversablity_estimation_net/scripts/pointnet_curv.py:25\u001b[0m, in \u001b[0;36mPointnetCurv.forward\u001b[0;34m(self, x, imu, batch)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, imu, batch):\n\u001b[1;32m     24\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x))\n\u001b[0;32m---> 25\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(x))\n\u001b[1;32m     26\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(x, dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)[\u001b[39m0\u001b[39m]  \u001b[39m# max pooling\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1(x))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    307\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    308\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    310\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss=[]\n",
    "test_mae=[]\n",
    "\n",
    "# Save every 10th epoch model.\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    \n",
    "    loss = train(model, optimizer, train_loader)\n",
    "    mae = test(model, test_loader)\n",
    "    if epoch % 50 == 0:\n",
    "        torch.save(model.state_dict(), f'epoch_{epoch}.pt')\n",
    "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, MAE: {mae:.4f}')\n",
    "    train_loss.append(loss)\n",
    "    test_mae.append(mae)\n",
    "    \n",
    "fig, (ax1, ax2) = plt.subplots(2, figsize=(12, 6), sharex=True)\n",
    "ax1.plot(train_loss)\n",
    "ax1.set_ylabel(\"training loss\")\n",
    "ax2.plot(test_mae)\n",
    "ax2.set_ylabel(\"mae error\")\n",
    "ax2.set_xlabel(\"epochs\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e57769",
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Load the model\n",
    "# print curdir()\n",
    "print(os.getcwd())\n",
    "\n",
    "net = PointnetCurv()\n",
    "net.load_state_dict(torch.load('/home/atas/RESEARCH/traversablity_estimation_net/scripts/epoch_100.pt'))\n",
    "net.eval()\n",
    "\n",
    "mae = 0.0\n",
    "for data in visual_test_loader:\n",
    " \n",
    "    inputs, labels = data.pos, data.y\n",
    "    inputs = inputs.reshape((inputs.shape[0], inputs.shape[1], 1))\n",
    "    outputs = net(inputs, data.x, data.batch)\n",
    "    \n",
    "    mae += criterion(outputs, data.y)        # Loss computation.\n",
    "    \n",
    "    outputs = outputs.cpu().detach().numpy()\n",
    "    labels = labels.cpu().detach().numpy()\n",
    "    \n",
    "    print(\"Predicted: \" + str(outputs) + \" Actual: \" + str(labels))\n",
    "\n",
    "mae = mae / len(visual_test_loader)\n",
    "print(\"MAE: \" + str(mae))    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
