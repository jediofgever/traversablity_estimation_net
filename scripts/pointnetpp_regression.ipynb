{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21f18528-1b6d-4996-96a4-78344252f43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu117\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import DatasetFolder\n",
    "from tqdm import tqdm\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53fd2094-83a1-49f2-a959-4ba5f6bf1544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from dataset import TerrainDataset\n",
    "from pointnet import PointNet\n",
    "\n",
    "dataset = TerrainDataset(root='/home/atas/traversablity_estimation_net/data',train=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f6029fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Javascript  # Restrict height of output cell.\n",
    "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_dataset =  TerrainDataset(root='/home/atas/traversablity_estimation_net/data', train=True )\n",
    "test_dataset = TerrainDataset(root='/home/atas/traversablity_estimation_net/data', train=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1)\n",
    "\n",
    "model = PointNet()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "#criterion = torch.nn.MSELoss()  # Mean Squared Error Loss Function\n",
    "criterion = torch.nn.L1Loss()  # Mean Absolute Error (L1 Loss Function)\n",
    "\n",
    "def train(model, optimizer, loader):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for data in loader:\n",
    "        optimizer.zero_grad()                   # Clear gradients.\n",
    "        # reshape to have 1 at the end\n",
    "        data.pos = data.pos.reshape((data.pos.shape[0], data.pos.shape[1], 1))\n",
    "        logits = model(data.pos, data.batch)                # Forward pass.\n",
    "        loss = criterion(logits, data.y)        # Loss computation.\n",
    "        loss.backward()                         # Backward pass.\n",
    "        optimizer.step()                        # Update model parameters.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, loader):\n",
    "    model.eval()\n",
    "\n",
    "    error = 0.0\n",
    "    for data in loader:\n",
    "        data.pos = data.pos.reshape((data.pos.shape[0], data.pos.shape[1], 1))\n",
    "        pred = model(data.pos, data.batch)\n",
    "        error += torch.pow((pred - data.y), 2).sum().item()\n",
    "    \n",
    "    # convert error to percentage accuracy\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "670dec50-952b-4115-b79d-b302b1b960b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 130.7308, MSE: 2.4487\n",
      "Epoch: 02, Loss: 81.5010, MSE: 2.4430\n",
      "Epoch: 03, Loss: 75.0338, MSE: 2.6037\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39m# Save every 10th epoch model.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m300\u001b[39m):\n\u001b[0;32m----> 6\u001b[0m     loss \u001b[39m=\u001b[39m train(model, optimizer, train_loader)\n\u001b[1;32m      7\u001b[0m     mse \u001b[39m=\u001b[39m test(model, test_loader)\n\u001b[1;32m      8\u001b[0m     \u001b[39mif\u001b[39;00m epoch \u001b[39m%\u001b[39m \u001b[39m50\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[4], line 20\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, loader)\u001b[0m\n\u001b[1;32m     18\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     19\u001b[0m total_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m---> 20\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m loader:\n\u001b[1;32m     21\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()                   \u001b[39m# Clear gradients.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[39m# reshape to have 1 at the end\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/loader/dataloader.py:20\u001b[0m, in \u001b[0;36mCollater.__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     18\u001b[0m elem \u001b[39m=\u001b[39m batch[\u001b[39m0\u001b[39m]\n\u001b[1;32m     19\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, BaseData):\n\u001b[0;32m---> 20\u001b[0m     \u001b[39mreturn\u001b[39;00m Batch\u001b[39m.\u001b[39;49mfrom_data_list(batch, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfollow_batch,\n\u001b[1;32m     21\u001b[0m                                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexclude_keys)\n\u001b[1;32m     22\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m     23\u001b[0m     \u001b[39mreturn\u001b[39;00m default_collate(batch)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/data/batch.py:76\u001b[0m, in \u001b[0;36mBatch.from_data_list\u001b[0;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m     65\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_data_list\u001b[39m(\u001b[39mcls\u001b[39m, data_list: List[BaseData],\n\u001b[1;32m     66\u001b[0m                    follow_batch: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     67\u001b[0m                    exclude_keys: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     68\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Constructs a :class:`~torch_geometric.data.Batch` object from a\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39m    Python list of :class:`~torch_geometric.data.Data` or\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[39m    :class:`~torch_geometric.data.HeteroData` objects.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39m    :obj:`follow_batch`.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[39m    Will exclude any keys given in :obj:`exclude_keys`.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     batch, slice_dict, inc_dict \u001b[39m=\u001b[39m collate(\n\u001b[1;32m     77\u001b[0m         \u001b[39mcls\u001b[39;49m,\n\u001b[1;32m     78\u001b[0m         data_list\u001b[39m=\u001b[39;49mdata_list,\n\u001b[1;32m     79\u001b[0m         increment\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     80\u001b[0m         add_batch\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(data_list[\u001b[39m0\u001b[39;49m], Batch),\n\u001b[1;32m     81\u001b[0m         follow_batch\u001b[39m=\u001b[39;49mfollow_batch,\n\u001b[1;32m     82\u001b[0m         exclude_keys\u001b[39m=\u001b[39;49mexclude_keys,\n\u001b[1;32m     83\u001b[0m     )\n\u001b[1;32m     85\u001b[0m     batch\u001b[39m.\u001b[39m_num_graphs \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(data_list)\n\u001b[1;32m     86\u001b[0m     batch\u001b[39m.\u001b[39m_slice_dict \u001b[39m=\u001b[39m slice_dict\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/data/collate.py:85\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[39m# Collate attributes into a unified representation:\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m value, slices, incs \u001b[39m=\u001b[39m _collate(attr, values, data_list, stores,\n\u001b[1;32m     86\u001b[0m                                increment)\n\u001b[1;32m     88\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, Tensor) \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mis_cuda:\n\u001b[1;32m     89\u001b[0m     device \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39mdevice\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/data/collate.py:128\u001b[0m, in \u001b[0;36m_collate\u001b[0;34m(key, values, data_list, stores, increment)\u001b[0m\n\u001b[1;32m    123\u001b[0m elem \u001b[39m=\u001b[39m values[\u001b[39m0\u001b[39m]\n\u001b[1;32m    125\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, Tensor):\n\u001b[1;32m    126\u001b[0m     \u001b[39m# Concatenate a list of `torch.Tensor` along the `cat_dim`.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m     \u001b[39m# NOTE: We need to take care of incrementing elements appropriately.\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39;49m(key)\n\u001b[1;32m    129\u001b[0m     cat_dim \u001b[39m=\u001b[39m data_list[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m__cat_dim__(key, elem, stores[\u001b[39m0\u001b[39m])\n\u001b[1;32m    130\u001b[0m     \u001b[39mif\u001b[39;00m cat_dim \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m elem\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss=[]\n",
    "test_mse=[]\n",
    "\n",
    "# Save every 10th epoch model.\n",
    "for epoch in range(1, 300):\n",
    "    loss = train(model, optimizer, train_loader)\n",
    "    mse = test(model, test_loader)\n",
    "    if epoch % 50 == 0:\n",
    "        torch.save(model.state_dict(), f'epoch_{epoch}.pt')\n",
    "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, MSE: {mse:.4f}')\n",
    "    train_loss.append(loss)\n",
    "    test_mse.append(mse)\n",
    "    \n",
    "fig, (ax1, ax2) = plt.subplots(2, figsize=(12, 6), sharex=True)\n",
    "ax1.plot(train_loss)\n",
    "ax1.set_ylabel(\"training loss\")\n",
    "ax2.plot(test_mse)\n",
    "ax2.set_ylabel(\"mse error\")\n",
    "ax2.set_xlabel(\"epochs\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47e57769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/atas/traversablity_estimation_net/scripts\n",
      "MSE: 0.049867856872803526\n"
     ]
    }
   ],
   "source": [
    "visual_test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Load the model\n",
    "# print curdir()\n",
    "print(os.getcwd())\n",
    "\n",
    "net = PointNet()\n",
    "net.load_state_dict(torch.load('/home/atas/traversablity_estimation_net/weights/epoch_200.pt'))\n",
    "net.eval()\n",
    "\n",
    "error = 0.0\n",
    "for data in visual_test_loader:\n",
    " \n",
    "    inputs, labels = data.pos, data.y\n",
    "    inputs = inputs.reshape((inputs.shape[0], inputs.shape[1], 1))\n",
    "    outputs = net(inputs, data.batch)\n",
    "    \n",
    "    error += torch.pow((outputs - data.y), 2).sum().item()\n",
    "    outputs = outputs.cpu().detach().numpy()\n",
    "    labels = labels.cpu().detach().numpy()\n",
    "\n",
    "error = error / len(visual_test_loader)\n",
    "print(\"MSE: \" + str(error))    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
